{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0643dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from -r requirements.txt (line 1)) (0.9.39)\n",
      "Requirement already satisfied: openai in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from -r requirements.txt (line 2)) (1.10.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from -r requirements.txt (line 3)) (4.0.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index->-r requirements.txt (line 1)) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (2023.12.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.66.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index->-r requirements.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from httpx->llama-index->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from httpx->llama-index->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from httpcore==1.*->httpx->llama-index->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from requests>=2.31.0->llama-index->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from requests>=2.31.0->llama-index->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from tqdm>4->openai->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from dataclasses-json->llama-index->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from pandas->llama-index->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from pandas->llama-index->-r requirements.txt (line 1)) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from pandas->llama-index->-r requirements.txt (line 1)) (2023.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shouv\\anaconda3\\envs\\ragllm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc53a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41cdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de64aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7272069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65673887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|███████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 471.83it/s]\n",
      "Generating embeddings: 100%|████████████████████████████████████████████████████████████████| 184/184 [00:02<00:00, 74.13it/s]\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c528a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9fc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query('what is google gemini?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c65c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Google Gemini is a family of highly capable multimodal\n",
      "models developed by Google. The Gemini family consists of three sizes:\n",
      "Ultra, Pro, and Nano, each tailored to address different computational\n",
      "limitations and application requirements. These models exhibit\n",
      "remarkable capabilities across image, audio, video, and text\n",
      "understanding. Gemini models have advanced the state of the art in\n",
      "various benchmarks, including language modeling, image understanding,\n",
      "audio processing, video understanding, speech recognition, and speech\n",
      "translation. The most capable model, Gemini Ultra, has achieved new\n",
      "state-of-the-art results in multiple benchmarks and is the first model\n",
      "to achieve human-expert performance on certain exams. The Gemini\n",
      "models' capabilities in cross-modal reasoning and language\n",
      "understanding enable a wide variety of use cases.\n",
      "______________________________________________________________________\n",
      "Source Node 1/2\n",
      "Node ID: e3240439-3a2e-410c-9cad-c0ef820bcbff\n",
      "Similarity: 0.839764929490381\n",
      "Text: Ordering within each role does not indicate ordering of the\n",
      "contributions. Gemini is a cross-Google effort, with members from\n",
      "Google DeepMind (GDM), Google Research (GR), Knowledge and Information\n",
      "(K&I), Core ML, Cloud, Labs, and more. We thank our reviewers and\n",
      "colleagues for their valuable discussions and feedback on the report —\n",
      "Alexandra Bel...\n",
      "______________________________________________________________________\n",
      "Source Node 2/2\n",
      "Node ID: 4b1a6aea-c68c-437b-98dc-e14b71f683d0\n",
      "Similarity: 0.8322034190844066\n",
      "Text: Gemini: A Family of Highly Capable Multimodal Models Gemini\n",
      "Team, Google1 This report introduces a new family of multimodal\n",
      "models, Gemini, that exhibit remarkable capabilities across image,\n",
      "audio, video, and text understanding. The Gemini family consists of\n",
      "Ultra, Pro, and Nano sizes, suitable for applications ranging from\n",
      "complex reasoning tas...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.response.pprint_utils import pprint_response \n",
    "\n",
    "pprint_response(response, show_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d054051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
    "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.80)\n",
    "\n",
    "query_engine=RetrieverQueryEngine(retriever=retriever,\n",
    "                                  node_postprocessors=[postprocessor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c2886a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=query_engine.query(\"What is google gemini?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d7ae1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Google Gemini is a family of highly capable multimodal\n",
      "models developed by Google. These models exhibit remarkable\n",
      "capabilities across image, audio, video, and text understanding. The\n",
      "Gemini family consists of three sizes: Ultra, Pro, and Nano, each\n",
      "tailored to address different computational limitations and\n",
      "application requirements. The most capable model, Gemini Ultra, has\n",
      "advanced the state of the art in various benchmarks and is the first\n",
      "model to achieve human-expert performance on the MMLU exam benchmark.\n",
      "Gemini models have new capabilities in cross-modal reasoning and\n",
      "language understanding, enabling a wide variety of use cases.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: e3240439-3a2e-410c-9cad-c0ef820bcbff\n",
      "Similarity: 0.8490490350548404\n",
      "Text: Ordering within each role does not indicate ordering of the\n",
      "contributions. Gemini is a cross-Google effort, with members from\n",
      "Google DeepMind (GDM), Google Research (GR), Knowledge and Information\n",
      "(K&I), Core ML, Cloud, Labs, and more. We thank our reviewers and\n",
      "colleagues for their valuable discussions and feedback on the report —\n",
      "Alexandra Bel...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: 4b1a6aea-c68c-437b-98dc-e14b71f683d0\n",
      "Similarity: 0.8431265008558901\n",
      "Text: Gemini: A Family of Highly Capable Multimodal Models Gemini\n",
      "Team, Google1 This report introduces a new family of multimodal\n",
      "models, Gemini, that exhibit remarkable capabilities across image,\n",
      "audio, video, and text understanding. The Gemini family consists of\n",
      "Ultra, Pro, and Nano sizes, suitable for applications ranging from\n",
      "complex reasoning tas...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: 2a0d0ab8-3cd8-4175-b2c1-067973031126\n",
      "Similarity: 0.8410562395193347\n",
      "Text: Gemini: A Family of Highly Capable Multimodal Models The roles\n",
      "are defined as below: •Lead: Individual(s) responsible for the sub-\n",
      "team throughout the project. •Core Contributor : Individual that had\n",
      "significant impact throughout the project. •Contributor : Individual\n",
      "that had contributions to the project and was partially involved with\n",
      "the effor...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: 601eac40-618d-4e7c-bdd1-d7ec7787942a\n",
      "Similarity: 0.8360435014204791\n",
      "Text: Gemini: A Family of Highly Capable Multimodal Models provides\n",
      "input and feedback on impact assessments, policies, evaluations and\n",
      "mitigation efforts. During the Gemini project, the RSC set specific\n",
      "evaluation targets across key policy domains (e.g. child safety). 7.\n",
      "Discussion and Conclusion We have presented Gemini, a new family of\n",
      "models that ...\n",
      "Google Gemini is a family of highly capable multimodal models developed by Google. These models exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of three sizes: Ultra, Pro, and Nano, each tailored to address different computational limitations and application requirements. The most capable model, Gemini Ultra, has advanced the state of the art in various benchmarks and is the first model to achieve human-expert performance on the MMLU exam benchmark. Gemini models have new capabilities in cross-modal reasoning and language understanding, enabling a wide variety of use cases.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.response.pprint_utils import pprint_response\n",
    "pprint_response(response,show_source=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea7f29f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Gemini refers to a family of highly capable multimodal models. It is a cross-Google effort involving members from various teams within Google, including Google DeepMind, Google Research, Knowledge and Information, Core ML, Cloud, Labs, and more. Gemini models are designed to have lead individuals responsible for sub-teams, core contributors who have had a significant impact on the project, contributors who have made contributions to the project, program leads responsible for the organizational aspects of the Gemini effort, and an overall technical lead responsible for the technical direction of the overall Gemini effort. The contributions within each role are equal and listed in a randomized order.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os.path\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are google gemini?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c839752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "ragllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
